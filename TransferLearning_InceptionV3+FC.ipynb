{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJDD93Au7O48"
   },
   "source": [
    "# Transfer Learning - InceptionV3+FC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yuSvDzToUNps"
   },
   "outputs": [],
   "source": [
    "# option to view all the outputs of a cell and not just the last one\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrpjqYBeUNpy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the seed for random operations. \n",
    "# This let our experiments to be reproducible. \n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED)  \n",
    "\n",
    "# Get current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "dataset_dir = '/content/drive/My Drive/NeuralNetwork_project/MaskDataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_rMz3ODmUxhT",
    "outputId": "e9ce5b9f-f854-458b-a684-f1b4015e6b02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# the original file was implemented in Google Colab to take advantage of the free GPU \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yy2BWar4UrIo",
    "outputId": "134a76a2-4b80-454b-8e64-c2805f1bd4d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# img shape (use those of the original architecture)\n",
    "img_h = 299\n",
    "img_w = 299\n",
    "\n",
    "# import the architecture \n",
    "from keras.applications.inception_v3 import preprocess_input \n",
    "base = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRAhPLiwBfSL"
   },
   "outputs": [],
   "source": [
    "# labels of the training set images are provided by a text file that matches each image to the corresponding class\n",
    "with open(os.path.join(dataset_dir,\"train_gt.json\")) as f:\n",
    "  dic = json.load(f)\n",
    "df = pd.DataFrame(dic.items())\n",
    "df.rename(columns = {0:'filename', 1:'class'}, inplace = True)\n",
    "df['class'] = df['class'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ey_sDmJuEFXY",
    "outputId": "e535f1ba-a76b-4d18-e753-a3883af7db96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    374\n",
       "0    373\n",
       "1    367\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# divide the dataset into training set and validation set, reserving 80% of the data for the training set\n",
    "# and 20% for the validation set (the total images in the dataset are 5600)\n",
    "df_shuffled = df.sample(frac=1, random_state=SEED).reset_index()\n",
    "df_train = df_shuffled.iloc[0:4500]\n",
    "df_valid = df_shuffled.iloc[4500:]\n",
    "\n",
    "# using stratified sampling is not necessary as the split already produces a balanced division, \n",
    "# as we can see in the following:\n",
    "df_valid[\"class\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYZWE5r-L4Lo"
   },
   "outputs": [],
   "source": [
    "# set the data augmentation parameters\n",
    "# (they are chosen in a way that modify the images as much as possible, without completely altering them)\n",
    "\n",
    "apply_data_augmentation = True\n",
    "\n",
    "# Create training ImageDataGenerator object\n",
    "if apply_data_augmentation:\n",
    "    train_data_gen = ImageDataGenerator(rotation_range=10,\n",
    "                                        width_shift_range=10,\n",
    "                                        height_shift_range=10,\n",
    "                                        zoom_range=0.3,\n",
    "                                        horizontal_flip=True,\n",
    "                                        brightness_range=(0.8,1.2),\n",
    "                                        shear_range=10,\n",
    "                                        channel_shift_range=150,\n",
    "                                        vertical_flip=False,\n",
    "                                        fill_mode='constant',\n",
    "                                        cval=0,\n",
    "                                        preprocessing_function=preprocess_input)  \n",
    "else:\n",
    "    train_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "valid_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MXfacUBJMuzc",
    "outputId": "1945204f-ff85-4c74-cfec-3f69a03fa048"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4500 validated image filenames belonging to 3 classes.\n",
      "Found 1114 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Batch size\n",
    "bs = 32\n",
    "\n",
    "num_classes=3\n",
    "\n",
    "training_dir = os.path.join(dataset_dir,\"training\")\n",
    "\n",
    "# Training\n",
    "train_gen = train_data_gen.flow_from_dataframe(df_train,\n",
    "                                               training_dir,\n",
    "                                               batch_size=bs, \n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=True,\n",
    "                                               target_size=(img_h,img_w),\n",
    "                                               seed=SEED)  \n",
    "\n",
    "# Validation\n",
    "valid_gen = valid_data_gen.flow_from_dataframe(df_valid,\n",
    "                                               training_dir,\n",
    "                                               batch_size=bs, \n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=False,\n",
    "                                               target_size=(img_h,img_w),\n",
    "                                               seed=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pOOYQqf4UNqB"
   },
   "outputs": [],
   "source": [
    "# Create Dataset objects\n",
    "# ----------------------\n",
    "\n",
    "# Training\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
    "\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "# Validation\n",
    "# ----------\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
    "\n",
    "valid_dataset = valid_dataset.repeat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2TLnEmFCfrud",
    "outputId": "899c7707-e9aa-49f4-eb57-304deec661b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "avg_pool (GlobalAveragePooli (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "top_dropout (Dropout)        (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 23,904,035\n",
      "Trainable params: 2,101,251\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create Model \n",
    "# ------------\n",
    "base.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=(img_h, img_w, 3))\n",
    "x = inputs\n",
    "x = base(x, training=False) \n",
    "# the \"training = False\" parameter allows to keep the batch normalization layers freezed, \n",
    "# even when the others will be made trainable\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "# add a FC layer with l2 regularization\n",
    "x = tf.keras.layers.Dense(units=1024, activation='relu', kernel_regularizer='l2')(x)\n",
    "# add a dropout layer to further control overfitting\n",
    "x = tf.keras.layers.Dropout(0.2, name=\"top_dropout\")(x)\n",
    "# final softmax for classification\n",
    "outputs = tf.keras.layers.Dense(units=num_classes, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Visualize created model as a table\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlDwCcHHgfQ-"
   },
   "outputs": [],
   "source": [
    "# Optimization params\n",
    "# -------------------\n",
    "\n",
    "# Loss\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-4\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "# -------------------\n",
    "\n",
    "# Validation metrics\n",
    "# ------------------\n",
    "\n",
    "metrics = ['accuracy']\n",
    "# ------------------\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nt-QO2OKjOSE",
    "outputId": "7ac31008-c20d-493c-db43-48205914c746"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "141/141 [==============================] - 1168s 8s/step - loss: 12.4636 - accuracy: 0.5773 - val_loss: 10.3878 - val_accuracy: 0.6777\n",
      "Epoch 2/15\n",
      "141/141 [==============================] - 152s 1s/step - loss: 9.0899 - accuracy: 0.6360 - val_loss: 7.7313 - val_accuracy: 0.6912\n",
      "Epoch 3/15\n",
      "141/141 [==============================] - 151s 1s/step - loss: 6.9015 - accuracy: 0.6520 - val_loss: 5.9887 - val_accuracy: 0.6822\n",
      "Epoch 4/15\n",
      "141/141 [==============================] - 152s 1s/step - loss: 5.3943 - accuracy: 0.6671 - val_loss: 4.7305 - val_accuracy: 0.7065\n",
      "Epoch 5/15\n",
      "141/141 [==============================] - 150s 1s/step - loss: 4.3486 - accuracy: 0.6727 - val_loss: 3.8515 - val_accuracy: 0.7047\n",
      "Epoch 6/15\n",
      "141/141 [==============================] - 149s 1s/step - loss: 3.5729 - accuracy: 0.6802 - val_loss: 3.2074 - val_accuracy: 0.7226\n",
      "Epoch 7/15\n",
      "141/141 [==============================] - 149s 1s/step - loss: 3.0075 - accuracy: 0.6784 - val_loss: 2.6961 - val_accuracy: 0.7101\n",
      "Epoch 8/15\n",
      "141/141 [==============================] - 145s 1s/step - loss: 2.5657 - accuracy: 0.6782 - val_loss: 2.3145 - val_accuracy: 0.7145\n",
      "Epoch 9/15\n",
      "141/141 [==============================] - 143s 1s/step - loss: 2.2236 - accuracy: 0.6864 - val_loss: 2.0009 - val_accuracy: 0.7163\n",
      "Epoch 10/15\n",
      "141/141 [==============================] - 140s 990ms/step - loss: 1.9661 - accuracy: 0.6811 - val_loss: 1.7874 - val_accuracy: 0.6939\n",
      "Epoch 11/15\n",
      "141/141 [==============================] - 138s 981ms/step - loss: 1.7411 - accuracy: 0.6820 - val_loss: 1.6253 - val_accuracy: 0.6894\n",
      "Epoch 12/15\n",
      "141/141 [==============================] - 137s 973ms/step - loss: 1.5641 - accuracy: 0.6853 - val_loss: 1.4458 - val_accuracy: 0.7110\n",
      "Epoch 13/15\n",
      "141/141 [==============================] - 137s 973ms/step - loss: 1.4266 - accuracy: 0.6991 - val_loss: 1.2941 - val_accuracy: 0.7092\n",
      "Epoch 14/15\n",
      "141/141 [==============================] - 137s 974ms/step - loss: 1.3234 - accuracy: 0.6876 - val_loss: 1.1928 - val_accuracy: 0.7136\n",
      "Epoch 15/15\n",
      "141/141 [==============================] - 136s 967ms/step - loss: 1.2218 - accuracy: 0.6878 - val_loss: 1.1212 - val_accuracy: 0.7083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4e50c679b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as recommended by Keras documentation, I do the first training keeping the base freezed\n",
    "model.fit(x=train_dataset,\n",
    "          epochs=15, \n",
    "          steps_per_epoch=len(train_gen),\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(valid_gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMrVLNrlwDnb"
   },
   "source": [
    "Now I proceed with fine tuning by unfreezing the base. I can decide whether to unlock all the layers of the base or just some. After trying both options, I found that unlocking all layers led to the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ea8LN4UeH3-"
   },
   "outputs": [],
   "source": [
    "#unfreeze only some layers \n",
    "# ------------\n",
    "#base.trainable = True\n",
    "#unfreeze=False\n",
    "#for layer in base.layers:\n",
    "#  layer.trainable=False\n",
    "#  if unfreeze and not (isinstance(layer, tf.keras.layers.BatchNormalization)):\n",
    "#    layer.trainable=True\n",
    "#  if layer.name=='mixed1': #it is possible to select also mixed2,3,4 and so on...\n",
    "#    unfreeze=True\n",
    "\n",
    "#model.compile(loss=loss, metrics=metrics, optimizer=tf.keras.optimizers.Adam(1e-4))\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nycRzxpCvFnl",
    "outputId": "7ef6c959-00bd-4bc1-d7c3-9920cdd75770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "avg_pool (GlobalAveragePooli (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "top_dropout (Dropout)        (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 23,904,035\n",
      "Trainable params: 23,869,603\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#unfreeze all the layers\n",
    "base.trainable = True\n",
    "model.compile(loss=loss, metrics=metrics, optimizer=tf.keras.optimizers.Adam(1e-4))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "buBq4uWfxCCE"
   },
   "outputs": [],
   "source": [
    "# plot to view the progress of the training\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/drive/My\\ Drive/NeuralNetwork_project/classification_experiments/ --port 6009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eLjlsMHhZ0sN"
   },
   "outputs": [],
   "source": [
    "# set the automatic saving checkpoints\n",
    "\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "exps_dir = os.path.join('/content/drive/My Drive/NeuralNetwork_project/', 'classification_experiments')\n",
    "if not os.path.exists(exps_dir):\n",
    "    os.makedirs(exps_dir)\n",
    "\n",
    "model_name = 'InceptionV3'\n",
    "\n",
    "exp_dir = os.path.join(exps_dir, model_name)\n",
    "if not os.path.exists(exp_dir):\n",
    "    os.makedirs(exp_dir)\n",
    "    \n",
    "callbacks = []\n",
    "\n",
    "# Model checkpoint\n",
    "# ----------------\n",
    "ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n",
    "                                                   save_weights_only=False)  \n",
    "\n",
    "callbacks.append(ckpt_callback)\n",
    "\n",
    "# Visualize Learning on Tensorboard\n",
    "# ---------------------------------\n",
    "tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "if not os.path.exists(tb_dir):\n",
    "    os.makedirs(tb_dir)\n",
    "    \n",
    "# By default shows losses and metrics for both training and validation\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                             profile_batch=0,\n",
    "                                             histogram_freq=1)  # if 1 shows weights histograms\n",
    "callbacks.append(tb_callback)\n",
    "\n",
    "# Early Stopping\n",
    "# --------------\n",
    "early_stop = True\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    callbacks.append(es_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GxuZ9lRoZpz1",
    "outputId": "db0bd32a-ec26-4304-b237-fa95291316df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2581 - accuracy: 0.5967WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_01.ckpt/assets\n",
      "141/141 [==============================] - 222s 2s/step - loss: 1.2581 - accuracy: 0.5967 - val_loss: 0.8519 - val_accuracy: 0.7648\n",
      "Epoch 2/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.7281 - accuracy: 0.8173INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_02.ckpt/assets\n",
      "141/141 [==============================] - 222s 2s/step - loss: 0.7281 - accuracy: 0.8173 - val_loss: 0.5687 - val_accuracy: 0.8851\n",
      "Epoch 3/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.5665 - accuracy: 0.8518INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_03.ckpt/assets\n",
      "141/141 [==============================] - 228s 2s/step - loss: 0.5665 - accuracy: 0.8518 - val_loss: 0.4303 - val_accuracy: 0.9013\n",
      "Epoch 4/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.4573 - accuracy: 0.8647INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_04.ckpt/assets\n",
      "141/141 [==============================] - 229s 2s/step - loss: 0.4573 - accuracy: 0.8647 - val_loss: 0.3707 - val_accuracy: 0.9147\n",
      "Epoch 5/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.3989 - accuracy: 0.8716INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_05.ckpt/assets\n",
      "141/141 [==============================] - 228s 2s/step - loss: 0.3989 - accuracy: 0.8716 - val_loss: 0.4726 - val_accuracy: 0.8555\n",
      "Epoch 6/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.3513 - accuracy: 0.8844INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_06.ckpt/assets\n",
      "141/141 [==============================] - 227s 2s/step - loss: 0.3513 - accuracy: 0.8844 - val_loss: 0.3766 - val_accuracy: 0.8662\n",
      "Epoch 7/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.3027 - accuracy: 0.8978INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_07.ckpt/assets\n",
      "141/141 [==============================] - 226s 2s/step - loss: 0.3027 - accuracy: 0.8978 - val_loss: 0.2501 - val_accuracy: 0.9255\n",
      "Epoch 8/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2956 - accuracy: 0.8987INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_08.ckpt/assets\n",
      "141/141 [==============================] - 226s 2s/step - loss: 0.2956 - accuracy: 0.8987 - val_loss: 0.2544 - val_accuracy: 0.9129\n",
      "Epoch 9/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2541 - accuracy: 0.9102INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_09.ckpt/assets\n",
      "141/141 [==============================] - 228s 2s/step - loss: 0.2541 - accuracy: 0.9102 - val_loss: 0.2313 - val_accuracy: 0.9255\n",
      "Epoch 10/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2444 - accuracy: 0.9127INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_10.ckpt/assets\n",
      "141/141 [==============================] - 229s 2s/step - loss: 0.2444 - accuracy: 0.9127 - val_loss: 0.2285 - val_accuracy: 0.9282\n",
      "Epoch 11/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2359 - accuracy: 0.9153INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_11.ckpt/assets\n",
      "141/141 [==============================] - 228s 2s/step - loss: 0.2359 - accuracy: 0.9153 - val_loss: 0.2558 - val_accuracy: 0.9022\n",
      "Epoch 12/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2173 - accuracy: 0.9238INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_12.ckpt/assets\n",
      "141/141 [==============================] - 228s 2s/step - loss: 0.2173 - accuracy: 0.9238 - val_loss: 0.2129 - val_accuracy: 0.9300\n",
      "Epoch 13/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2216 - accuracy: 0.9187INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_13.ckpt/assets\n",
      "141/141 [==============================] - 227s 2s/step - loss: 0.2216 - accuracy: 0.9187 - val_loss: 0.1847 - val_accuracy: 0.9372\n",
      "Epoch 14/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2092 - accuracy: 0.9256INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_14.ckpt/assets\n",
      "141/141 [==============================] - 228s 2s/step - loss: 0.2092 - accuracy: 0.9256 - val_loss: 0.1831 - val_accuracy: 0.9363\n",
      "Epoch 15/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2066 - accuracy: 0.9284INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_15.ckpt/assets\n",
      "141/141 [==============================] - 227s 2s/step - loss: 0.2066 - accuracy: 0.9284 - val_loss: 0.2138 - val_accuracy: 0.9354\n",
      "Epoch 16/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2021 - accuracy: 0.9273INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_16.ckpt/assets\n",
      "141/141 [==============================] - 228s 2s/step - loss: 0.2021 - accuracy: 0.9273 - val_loss: 0.1665 - val_accuracy: 0.9399\n",
      "Epoch 17/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1877 - accuracy: 0.9333INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_17.ckpt/assets\n",
      "141/141 [==============================] - 228s 2s/step - loss: 0.1877 - accuracy: 0.9333 - val_loss: 0.1697 - val_accuracy: 0.9381\n",
      "Epoch 18/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1964 - accuracy: 0.9304INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_18.ckpt/assets\n",
      "141/141 [==============================] - 226s 2s/step - loss: 0.1964 - accuracy: 0.9304 - val_loss: 0.2180 - val_accuracy: 0.9237\n",
      "Epoch 19/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1817 - accuracy: 0.9369INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_19.ckpt/assets\n",
      "141/141 [==============================] - 225s 2s/step - loss: 0.1817 - accuracy: 0.9369 - val_loss: 0.1779 - val_accuracy: 0.9408\n",
      "Epoch 20/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1820 - accuracy: 0.9344INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_20.ckpt/assets\n",
      "141/141 [==============================] - 226s 2s/step - loss: 0.1820 - accuracy: 0.9344 - val_loss: 0.1805 - val_accuracy: 0.9327\n",
      "Epoch 21/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1837 - accuracy: 0.9322INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_21.ckpt/assets\n",
      "141/141 [==============================] - 229s 2s/step - loss: 0.1837 - accuracy: 0.9322 - val_loss: 0.2303 - val_accuracy: 0.9264\n",
      "Epoch 22/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1754 - accuracy: 0.9402INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_22.ckpt/assets\n",
      "141/141 [==============================] - 231s 2s/step - loss: 0.1754 - accuracy: 0.9402 - val_loss: 0.1576 - val_accuracy: 0.9452\n",
      "Epoch 23/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1710 - accuracy: 0.9376INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_23.ckpt/assets\n",
      "141/141 [==============================] - 237s 2s/step - loss: 0.1710 - accuracy: 0.9376 - val_loss: 0.1725 - val_accuracy: 0.9479\n",
      "Epoch 24/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1575 - accuracy: 0.9442INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_24.ckpt/assets\n",
      "141/141 [==============================] - 235s 2s/step - loss: 0.1575 - accuracy: 0.9442 - val_loss: 0.2478 - val_accuracy: 0.9031\n",
      "Epoch 25/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1618 - accuracy: 0.9436INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_25.ckpt/assets\n",
      "141/141 [==============================] - 235s 2s/step - loss: 0.1618 - accuracy: 0.9436 - val_loss: 0.1990 - val_accuracy: 0.9363\n",
      "Epoch 26/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1340 - accuracy: 0.9547INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_26.ckpt/assets\n",
      "141/141 [==============================] - 233s 2s/step - loss: 0.1340 - accuracy: 0.9547 - val_loss: 0.1907 - val_accuracy: 0.9219\n",
      "Epoch 27/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1399 - accuracy: 0.9507INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_27.ckpt/assets\n",
      "141/141 [==============================] - 234s 2s/step - loss: 0.1399 - accuracy: 0.9507 - val_loss: 0.1518 - val_accuracy: 0.9408\n",
      "Epoch 28/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1560 - accuracy: 0.9422INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_28.ckpt/assets\n",
      "141/141 [==============================] - 236s 2s/step - loss: 0.1560 - accuracy: 0.9422 - val_loss: 0.1950 - val_accuracy: 0.9363\n",
      "Epoch 29/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1342 - accuracy: 0.9498INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_29.ckpt/assets\n",
      "141/141 [==============================] - 237s 2s/step - loss: 0.1342 - accuracy: 0.9498 - val_loss: 0.2297 - val_accuracy: 0.9291\n",
      "Epoch 30/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1370 - accuracy: 0.9498INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_30.ckpt/assets\n",
      "141/141 [==============================] - 237s 2s/step - loss: 0.1370 - accuracy: 0.9498 - val_loss: 0.1628 - val_accuracy: 0.9434\n",
      "Epoch 31/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1348 - accuracy: 0.9549INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_31.ckpt/assets\n",
      "141/141 [==============================] - 234s 2s/step - loss: 0.1348 - accuracy: 0.9549 - val_loss: 0.1760 - val_accuracy: 0.9452\n",
      "Epoch 32/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1317 - accuracy: 0.9544INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_32.ckpt/assets\n",
      "141/141 [==============================] - 238s 2s/step - loss: 0.1317 - accuracy: 0.9544 - val_loss: 0.1685 - val_accuracy: 0.9372\n",
      "Epoch 33/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1405 - accuracy: 0.9484INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_33.ckpt/assets\n",
      "141/141 [==============================] - 236s 2s/step - loss: 0.1405 - accuracy: 0.9484 - val_loss: 0.1724 - val_accuracy: 0.9443\n",
      "Epoch 34/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1151 - accuracy: 0.9604INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_34.ckpt/assets\n",
      "141/141 [==============================] - 234s 2s/step - loss: 0.1151 - accuracy: 0.9604 - val_loss: 0.1559 - val_accuracy: 0.9533\n",
      "Epoch 35/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 0.9624INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_35.ckpt/assets\n",
      "141/141 [==============================] - 233s 2s/step - loss: 0.1078 - accuracy: 0.9624 - val_loss: 0.1582 - val_accuracy: 0.9515\n",
      "Epoch 36/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.9571INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_36.ckpt/assets\n",
      "141/141 [==============================] - 233s 2s/step - loss: 0.1152 - accuracy: 0.9571 - val_loss: 0.1549 - val_accuracy: 0.9452\n",
      "Epoch 37/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9658INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/InceptionV3/ckpts/cp_37.ckpt/assets\n",
      "141/141 [==============================] - 231s 2s/step - loss: 0.0996 - accuracy: 0.9658 - val_loss: 0.1823 - val_accuracy: 0.9336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4e6250e2b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final training\n",
    "model.fit(x=train_dataset,\n",
    "          epochs=100,  #### set repeat in training dataset\n",
    "          steps_per_epoch=len(train_gen),\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(valid_gen), \n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32-OGEOM58X-",
    "outputId": "b8995e2e-9e3e-46b4-af26-6fb7776434db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/NeuralNetwork_project/classification_experiments/inceptionV3/assets\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "model.save('/content/drive/My Drive/NeuralNetwork_project/classification_experiments/inceptionV3') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDE-i1OP6UXJ"
   },
   "outputs": [],
   "source": [
    "# create the csv file for the submission on Kaggle\n",
    "import os\n",
    "\n",
    "def create_csv(results, results_dir='/content/drive/My Drive/NeuralNetwork_project'):\n",
    "\n",
    "    csv_fname = 'results_InceptionV3.csv'\n",
    "\n",
    "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
    "\n",
    "        f.write('Id,Category\\n')\n",
    "\n",
    "        for key, value in results.items():\n",
    "            f.write(key + ',' + str(value) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YNYFpF016Xrf"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# ....\n",
    "\n",
    "test_dir = '/content/drive/My Drive/NeuralNetwork_project/MaskDataset/test/'\n",
    "image_filenames = next(os.walk(test_dir))[2]\n",
    "\n",
    "results = {}\n",
    "for image_name in image_filenames:\n",
    "   img = Image.open(test_dir + image_name).convert('RGB')\n",
    "   img = img.resize((img_h,img_w))\n",
    "   img_array = np.array(img)\n",
    "   img_array = np.expand_dims(img_array, 0) \n",
    "   img_array = preprocess_input(img_array)\n",
    "   softmax = model.predict(img_array)\n",
    "   prediction = np.argmax(softmax)  \n",
    "   results[image_name] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Ln2H4_f6aAC"
   },
   "outputs": [],
   "source": [
    "create_csv(results)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TransferLearning_InceptionV3+FC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
